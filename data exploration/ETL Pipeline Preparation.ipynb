{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline Preparation\n",
    "Follow the instructions below to help you create your ETL pipeline.\n",
    "### 1. Import libraries and load datasets.\n",
    "- Import Python libraries\n",
    "- Load `messages.csv` into a dataframe and inspect the first few lines.\n",
    "- Load `categories.csv` into a dataframe and inspect the first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                            message  \\\n",
      "0   2  Weather update - a cold front from Cuba that c...   \n",
      "1   7            Is the Hurricane over or is it not over   \n",
      "2   8                    Looking for someone but no name   \n",
      "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
      "4  12  says: west side of Haiti, rest of the country ...   \n",
      "\n",
      "                                            original   genre  \n",
      "0  Un front froid se retrouve sur Cuba ce matin. ...  direct  \n",
      "1                 Cyclone nan fini osinon li pa fini  direct  \n",
      "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct  \n",
      "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct  \n",
      "4  facade ouest d Haiti et le reste du pays aujou...  direct  \n",
      "\n",
      "(26248, 4)\n"
     ]
    }
   ],
   "source": [
    "# load messages dataset\n",
    "messages = pd.read_csv('../data/disaster_messages.csv')\n",
    "print(messages.head())\n",
    "print()\n",
    "print(messages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-1;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>related-1;request-1;offer-0;aid_related-1;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         categories\n",
       "0   2  related-1;request-0;offer-0;aid_related-0;medi...\n",
       "1   7  related-1;request-0;offer-0;aid_related-1;medi...\n",
       "2   8  related-1;request-0;offer-0;aid_related-0;medi...\n",
       "3   9  related-1;request-1;offer-0;aid_related-1;medi...\n",
       "4  12  related-1;request-0;offer-0;aid_related-0;medi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load categories dataset\n",
    "categories = pd.read_csv('../data/disaster_categories.csv')\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge datasets.\n",
    "- Merge the messages and categories datasets using the common id\n",
    "- Assign this combined dataset to `df`, which will be cleaned in the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-1;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-1;offer-0;aid_related-1;medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct   \n",
       "\n",
       "                                          categories  \n",
       "0  related-1;request-0;offer-0;aid_related-0;medi...  \n",
       "1  related-1;request-0;offer-0;aid_related-1;medi...  \n",
       "2  related-1;request-0;offer-0;aid_related-0;medi...  \n",
       "3  related-1;request-1;offer-0;aid_related-1;medi...  \n",
       "4  related-1;request-0;offer-0;aid_related-0;medi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge datasets\n",
    "\n",
    "# use inner join as this removes entries that have eighter missing messages  \n",
    "# OR missing categories. Neighter of these would be of any use later on.\n",
    "df = pd.merge(messages, categories, how='inner', on=['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split `categories` into separate category columns.\n",
    "- Split the values in the `categories` column on the `;` character so that each value becomes a separate column. You'll find [this method](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.str.split.html) very helpful! Make sure to set `expand=True`.\n",
    "- Use the first row of categories dataframe to create column names for the categories data.\n",
    "- Rename columns of `categories` with new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    related-1\n",
      "1    related-1\n",
      "2    related-1\n",
      "3    related-1\n",
      "4    related-1\n",
      "Name: 0, dtype: object\n",
      "0    related\n",
      "1    related\n",
      "2    related\n",
      "3    related\n",
      "4    related\n",
      "Name: 0, dtype: object\n",
      "0    related-1\n",
      "1    related-1\n",
      "2    related-1\n",
      "3    related-1\n",
      "4    related-1\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "transform_cat_df = categories['categories'].str.split(';', expand=True)\n",
    "print(transform_cat_df[0].head())\n",
    "print(transform_cat_df[0].str.replace('-\\d*', '').head())\n",
    "print(transform_cat_df[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]  1 related\n",
      "[*]  2 request\n",
      "[*]  3 offer\n",
      "[*]  4 aid_related\n",
      "[*]  5 medical_help\n",
      "[*]  6 medical_products\n",
      "[*]  7 search_and_rescue\n",
      "[*]  8 security\n",
      "[*]  9 military\n",
      "[*] 10 child_alone\n",
      "[*] 11 water\n",
      "[*] 12 food\n",
      "[*] 13 shelter\n",
      "[*] 14 clothing\n",
      "[*] 15 money\n",
      "[*] 16 missing_people\n",
      "[*] 17 refugees\n",
      "[*] 18 death\n",
      "[*] 19 other_aid\n",
      "[*] 20 infrastructure_related\n",
      "[*] 21 transport\n",
      "[*] 22 buildings\n",
      "[*] 23 electricity\n",
      "[*] 24 tools\n",
      "[*] 25 hospitals\n",
      "[*] 26 shops\n",
      "[*] 27 aid_centers\n",
      "[*] 28 other_infrastructure\n",
      "[*] 29 weather_related\n",
      "[*] 30 floods\n",
      "[*] 31 storm\n",
      "[*] 32 fire\n",
      "[*] 33 earthquake\n",
      "[*] 34 cold\n",
      "[*] 35 other_weather\n",
      "[*] 36 direct_report\n",
      "\n",
      "[*] Found 36 labels\n",
      "[*] All columns have a unique label\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "messy_columns = []\n",
    "\n",
    "for i in transform_cat_df.columns:\n",
    "    # check if each column contains only one label (<label>-<set|unset>)\n",
    "#    work_df[i].str.split('-')\n",
    "    col_i_series = transform_cat_df[i].str.replace('-\\d*', '')\n",
    "    transform_cat_df[i] = transform_cat_df[i].str.replace('.*-', '').astype(int)\n",
    "    eq = col_i_series.value_counts() == transform_cat_df.shape[0]\n",
    "    if( eq.all() ):\n",
    "        label = col_i_series[0]\n",
    "        labels.append(label)\n",
    "        print(\"[*] {:2} {}\".format(len(labels), label))\n",
    "    else:\n",
    "        messy_columns.append(i)\n",
    "        print(\"[>] Column {} has mixed labels\".format(i))\n",
    "        \n",
    "print()\n",
    "print(\"[*] Found {} labels\".format(len(labels)))\n",
    "if( len(labels) == len(transform_cat_df.columns) ):\n",
    "    print(\"[*] All columns have a unique label\")\n",
    "else:\n",
    "    print(\"[x] Some columns are ambigous! Take a closer look at columns {}\".format(messy_columns))\n",
    "    \n",
    "len_of_uniques = len(set(labels))\n",
    "if(len_of_uniques != len(labels)):\n",
    "    print(\"[x] Found {} duplicate labels\".format(len(labels)-len_of_uniques))\n",
    "    \n",
    "\n",
    "transform_cat_df.columns = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "2        1        0      0            0             0                 0   \n",
       "3        1        1      0            1             0                 1   \n",
       "4        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  \\\n",
       "0                  0         0         0            0  ...   \n",
       "1                  0         0         0            0  ...   \n",
       "2                  0         0         0            0  ...   \n",
       "3                  0         0         0            0  ...   \n",
       "4                  0         0         0            0  ...   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "4                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  id  \n",
       "0     0              0              0   2  \n",
       "1     0              0              0   7  \n",
       "2     0              0              0   8  \n",
       "3     0              0              0   9  \n",
       "4     0              0              0  12  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_cat_df['id'] = categories['id']\n",
    "categories = transform_cat_df\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe of the 36 individual category columns\n",
    "df = pd.merge(messages, categories, how='inner', on=['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first row of the categories dataframe\n",
    "row = \n",
    "\n",
    "# use this row to extract a list of new column names for categories.\n",
    "# one way is to apply a lambda function that takes everything \n",
    "# up to the second to last character of each string with slicing\n",
    "category_colnames = \n",
    "print(category_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns of `categories`\n",
    "categories.columns = category_colnames\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convert category values to just numbers 0 or 1.\n",
    "- Iterate through the category columns in df to keep only the last character of each string (the 1 or 0). For example, `related-0` becomes `0`, `related-1` becomes `1`. Convert the string to a numeric value.\n",
    "- You can perform [normal string actions on Pandas Series](https://pandas.pydata.org/pandas-docs/stable/text.html#indexing-with-str), like indexing, by including `.str` after the Series. You may need to first convert the Series to be of type string, which you can do with `astype(str)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categories:\n",
    "    # set each value to be the last character of the string\n",
    "    categories[column] = \n",
    "    \n",
    "    # convert column from string to numeric\n",
    "    categories[column] = \n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Replace `categories` column in `df` with new category columns.\n",
    "- Drop the categories column from the df dataframe since it is no longer needed.\n",
    "- Concatenate df and categories data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original categories column from `df`\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the original dataframe with the new `categories` dataframe\n",
    "df = \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Remove duplicates.\n",
    "- Check how many duplicates are in this dataset.\n",
    "- Drop the duplicates.\n",
    "- Confirm duplicates were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4x    202\n",
      " 4x    804\n",
      " 4x    862\n",
      " 4x   1652\n",
      " 4x   2446\n",
      " 4x   3217\n",
      " 4x   3250\n",
      " 4x   3882\n",
      " 4x   4412\n",
      " 4x   4956\n",
      " 4x   5153\n",
      " 4x   5265\n",
      " 4x   5573\n",
      " 4x   5643\n",
      " 4x   5776\n",
      " 4x   6327\n",
      " 4x   6393\n",
      " 4x   6492\n",
      " 4x   6515\n",
      " 4x   6573\n",
      " 4x   6687\n",
      " 4x   7747\n",
      " 4x   7892\n",
      " 4x   7945\n",
      " 4x   8190\n",
      " 4x   9131\n",
      " 4x  10286\n",
      " 4x  11503\n",
      " 4x  12416\n",
      " 4x  12420\n",
      " 4x  12589\n",
      " 4x  13059\n",
      " 4x  13914\n",
      " 4x  14073\n",
      " 4x  14135\n",
      " 4x  14246\n",
      " 4x  14592\n",
      " 4x  15169\n",
      " 4x  15576\n",
      " 4x  15760\n",
      " 4x  15938\n",
      " 4x  16245\n",
      " 4x  17079\n",
      " 4x  17385\n",
      " 4x  17553\n",
      " 4x  17569\n",
      " 4x  17919\n",
      " 4x  18313\n",
      " 4x  18925\n",
      " 4x  19003\n",
      " 4x  19142\n",
      " 4x  19687\n",
      " 4x  21338\n",
      " 4x  22059\n",
      " 4x  22858\n",
      " 4x  23002\n",
      " 4x  23229\n",
      " 4x  24247\n",
      " 4x  24347\n",
      " 9x  24779\n",
      " 4x  25512\n",
      " 4x  27296\n",
      " 4x  27768\n",
      " 4x  28462\n",
      " 4x  28687\n",
      " 4x  29022\n",
      " 4x  29119\n",
      " 4x    MAOZA          U  REP '\n",
      " 4x #NAME?\n",
      " 4x (Delmas 33 Charboniere infomatyon s'il vous plait.) \n",
      " 4x * German Agro Action (GAA) reported that in the 6 weeks up to 15 July it had completed the distribution of ECHO food to almost 14,000 beneficiaries in the Tavildara district, as well as financing a total of 49 Food for Work micro-projects through WFP - the majority concerned with irrigation, canal cleaning and feeder road construction in the Garm district.\n",
      " 4x ?? port au prince ?? and food. they need goverment aid and international aid thak you. god bless haiti\n",
      " 4x Additionally, ointment to treat skin infections, cough medicine, iodine and bandages are needed for basic care.\n",
      " 4x After the 2011 elections, widespread rioting left hundreds dead.\n",
      " 4x All #NYC bridges, tunnels &amp; mta closed; over 2.8 million without power #Sandy causing So much havoc!!! Praying 4 us all\n",
      " 4x An EU-backed French offensive against rebels restored an uneasy order, but foreign donors have insisted on the elections before aid is resumed to Mali.\n",
      " 4x Any person who enters or exits at other points will be considered an infiltrator, he added.\n",
      " 4x Area Jam gulab pahore Area ghulam haidar pahore's almost 50 houses have been damaged due to the recent flood. Din't receive housing compensation. C.M. of punjab has given only one bedsheet per family and nothing else has been given. Due to cool weather children have been suffering from diseases.\n",
      " 4x As the harsh winter sets in, more people are in danger of dying in the freezing conditions.\n",
      " 4x As we approach Luabo, I get my first impressions of the camp, dilapidated buildings, most without roofs, or windows and walls collapsing.\n",
      " 4x At present, UNHCR has 2,500 additional tents at the Port of Colombo which have been granted duty free clearance by the Ministry of Foreign Affairs and are awaiting clearance for distribution.\n",
      " 4x BEIJING, Aug 16 (AFP) - Some 200 people are dead or missing following three days of flash flooding that hit central China's Hunan province, officials said Monday.\n",
      " 4x BEIJING, Sep 24, 2008 (Xinhua via COMTEX News Network) -- Typhoon Hagupit has downgraded to severe tropical storm at 2 p.m. Wednesday in coastal areas of South China's Guangxi Zhuang Autonomous Region, according to the National Meteorological Center.\n",
      " 4x Before we take your general questions, I'd like to make a few opening remarks concerning ISAF support to the Afghan people during these frigid winter months. After the earthquake, huge boulders blocked off the road to large vehicles. Most years, floods wreak havoc in the state, leaving a trail of destruction and killing hundreds of people. We have heard of crocodile sightings.\n",
      " 4x But while floodwaters have subsided in some areas, there has been fresh flooding in the north of the state and more heavy rainfall forecast elsewhere.\n",
      " 4x Falta tan tan poco.. ¬¨¬¥Simply Red - Holding back the years¬¨¬™. Arena Santiago, de all‚àö¬∞ somos! Night.  http://blip.fm/~n0frf\n",
      " 4x Full Circle, my local, collecting supplies and making lunches for #SandyRelief @Full Circle Bar http://t.co/EHLqbhHw\n",
      " 4x Good evening staff of responsibles, please give me some help because until now I am homeless (in the street). \n",
      " 4x Good evening. we are writing to ask you for a little help in the Sibert area. We are calling for something to eat. We haven't eaten anything yet. We ask you please do us a favor. \n",
      " 4x Good morning!How are you doing my brothers when the cyclone start and when it will be finish. \n",
      " 4x HELP THE EARTHQUAKE VICTIMS IN HAITI http tinyurl.com yk3bspe links to many resources where you can make donations. Broke? donate time\n",
      " 4x How much money did TV Latino American collect in Miami\n",
      " 4x I am a victim. I need food, water and a radio. \n",
      " 4x I am in Carefour Feuilles, Dkayet neighborhood. We need potable water because diarrhea is rampant here and is undermining our health. \n",
      " 4x I can help deliver food to seniors who are trapped in their homes . I speak Mandarin and Cantonese .\n",
      " 4x I have men and woman clothing plus 3-4t girl clothing , Toys , Non perishable food\n",
      " 4x I thought you gave my number and this was serious. Meanwhile today has been 15 days and we still haven't gotten anything\n",
      " 4x I would like some more informations about travelling to Senegal \n",
      " 4x I would like to find some informations about these questions that i asked. \n",
      " 4x I'd like to know an email to find a job \n",
      " 4x I'd like to sign up in the 4636 program please \n",
      " 4x If I would like to find a job in cepoz, what should I do? \n",
      " 4x In a field in Jallouzai, just inside Pakistan, 80,000 Afghans are jammed in without proper shelter, sanitation or water.\n",
      " 4x In response to North Korea's devastating artillery attack on Yeonpyeong Island on Tuesday, South Korea has suspended aid shipments of food and cement to the North's flood-stricken Shinuiju region.\n",
      " 4x It was offshore about 130 km to the southeast of Wenchang City on the east coast of Hainan and packing wind of up to force 8.\n",
      " 4x Me and my family every time it rains you do not know what to do, because we have nothing to shelter, please find us something that we live in a military cites the legal street pole. \n",
      " 4x Mera ghar selab ki waja sy gir giya hy. aur dobara nahin bna sakta main shadeed mooshkil men hoon. mery 3 choty choty bachy aur baqi ghar waly shdeed sardi khaema mein guzarny par majboor hin. khdara ghar banany mein meri mdad kro. plz help me. khalil\n",
      " 4x Most victims (90 per cent) show little or no symptoms of infection and therefore go a long time untreated, even though the World Health Organisation lists fever, fatigue, headache, vomiting, stiffness in the neck, and pain in the limbs as initial symptoms.\n",
      " 4x NOTES: this sms is not important because this person is playing.\n",
      " 4x On behalf of ACT members in Bangladesh Christian Commission for Development in Bangladesh (CCDB) and Rangpur Dinajpur Rural Service (RDRS) - LWF/WS report that none of their projects has yet been affected but that the low-lying areas of the north-eastern districts have been inundated by an on-rush of floodwater from across the border following rains and overflowing rivers in the neighbouring Indian state of Assam.\n",
      " 4x Sent email , matched to Seniors are living in the Seward Park Co-Op top floors with no power or water .\n",
      " 9x Shelter materials (thick polyesters) are being distributed to 18,000 households.\n",
      " 4x Sir or madam, I'm hungry, I cannot stand because I'm very hungry, if you could share the food, it would benefit the population, thanks\n",
      " 4x Some herders now have their homes connected to the town grid or, in the most isolated areas, herders have been provided with solar panels and small wind turbine systems as sources of renewable energy.\n",
      " 4x Starting in October 1999, severe food insecurity began to be reported in Gode zone, Somali Region, as a result of delayed and erratic Deyr rains (expected from September-December).\n",
      " 4x Tell the President to give the nation over to God. \n",
      " 4x The Management Committee is composed of six members, including a chairman, a treasurer, a secretary general, a manager and two commissioners elected democratically by the community.\n",
      " 4x The flood situation has worsened with nearly 3,000 villages submerged forcing an estimated 150,000 people to take shelter in raised platforms and makeshift tarpaulin tents, Assam Revenue, Relief and Rehabilitation Minister Bhumidhar Barman said.\n",
      " 4x The last locust infestation in the Central Asian republic was in 1995 and is expected to reoccur every four to five years.\n",
      " 4x The regime says the charter will clear the way for democratic elections in two years, but critics say the document will ensure the generals remain dominant in a country that has been ruled by the military for nearly half a century.\n",
      " 4x The slow pace of reconstruction along Japan's devastated north-eastern coastline is contributing to survivors' stress, as there is little clarity on how long they will have to remain in cramped temporary housing.\n",
      " 4x They reported sporadic rains were still flooding air fields, roads and slowing urgent repairs along several key highways.\n",
      " 4x To date, a total of 39 people suffering from Ebola or having had a high risk exposure to the virus, have been medically evacuated to Europe.\n",
      " 4x Wand to donate jackets , hot meals , non-perishable foods , towels , bed sheets\n",
      " 4x What can i do to protect my self if the earthquake comes back? \n",
      " 4x What is the address of the radio station? I ask because I need to drop off a file for the committee we created. Thanks in advance!\n",
      " 4x What we saw yesterday is a sign, you need to know what Jesus is stirring up/doing \n",
      " 4x World Vision staff stationed in Jabouri immediately reached the mudslide area to offer assistance.\n",
      " 4x elle est vraiment malade et a besoin d'aide. utilisez mon numero de tlphone pour obtenir plus de renseignements. Nous attendons une reponse. Aucun numero fourni par contre.\n",
      " 4x here,i'm i don't find medicin just resting to die where i can find it? \n",
      " 4x in my village after collapse of whole infrastructure due to flood the majority of people is homeless  in need of tents which are not available.\n",
      " 4x jel2  Acte 5: 29 2chr7 Lev11 Ecl9 Ecl4 jos5 ch102kr Es59 \n",
      " 4x please we need water, food and tents, we have 101 chlidren. .. please come rescue\n",
      " 4x there are people in Delmas 32 who form an association who is taking food on the name of the people in that neighborhood. they are just keeping it. it is not being distributed. \n",
      " 4x where we can paticipate in the law reorganizations? \n"
     ]
    }
   ],
   "source": [
    "# check number of duplicates\n",
    "def print_duplicates(df, column:str):\n",
    "    unique_dates, count = np.unique(df[column].tolist(), return_counts=True)\n",
    "\n",
    "    found_none_unique = False\n",
    "    for i in range(len(unique_dates)):\n",
    "        if count[i] >= 2:\n",
    "            print(\"{:2}x {:6}\".format(count[i], unique_dates[i]))\n",
    "            found_none_unique = True\n",
    "\n",
    "    if( not found_none_unique ): \n",
    "        print(\"No duplicates in column {}\".format(column))\n",
    "        \n",
    "print_duplicates(df, 'id')\n",
    "print_duplicates(df, 'message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove missing messages\n",
    "df = df[df['message'] != '#NAME?']\n",
    "df.loc[df['related'] > 1, 'related'] = 1\n",
    "print()\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(subset=['id', 'message'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                            0\n",
      "message                       0\n",
      "original                  16023\n",
      "genre                         0\n",
      "related                       0\n",
      "request                       0\n",
      "offer                         0\n",
      "aid_related                   0\n",
      "medical_help                  0\n",
      "medical_products              0\n",
      "search_and_rescue             0\n",
      "security                      0\n",
      "military                      0\n",
      "child_alone                   0\n",
      "water                         0\n",
      "food                          0\n",
      "shelter                       0\n",
      "clothing                      0\n",
      "money                         0\n",
      "missing_people                0\n",
      "refugees                      0\n",
      "death                         0\n",
      "other_aid                     0\n",
      "infrastructure_related        0\n",
      "transport                     0\n",
      "buildings                     0\n",
      "electricity                   0\n",
      "tools                         0\n",
      "hospitals                     0\n",
      "shops                         0\n",
      "aid_centers                   0\n",
      "other_infrastructure          0\n",
      "weather_related               0\n",
      "floods                        0\n",
      "storm                         0\n",
      "fire                          0\n",
      "earthquake                    0\n",
      "cold                          0\n",
      "other_weather                 0\n",
      "direct_report                 0\n",
      "dtype: int64\n",
      "No duplicates in column id\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.05 GiB for an array with shape (26176,) and data type <U10818",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-2b5d610bfac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-9e30910df5d6>\u001b[0m in \u001b[0;36mprint_duplicates\u001b[1;34m(df, column)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check number of duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfound_none_unique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.05 GiB for an array with shape (26176,) and data type <U10818"
     ]
    }
   ],
   "source": [
    "# check number of duplicates\n",
    "\n",
    "print(df.isna().sum())\n",
    "print_duplicates(df, 'id')\n",
    "print_duplicates(df, 'message')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['related'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save the clean dataset into an sqlite database.\n",
    "You can do this with pandas [`to_sql` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html) combined with the SQLAlchemy library. Remember to import SQLAlchemy's `create_engine` in the first cell of this notebook to use it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///DisasterMessageClassification.sqlite')\n",
    "df.to_sql('Messages', engine, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Use this notebook to complete `etl_pipeline.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database based on new datasets specified by the user. Alternatively, you can complete `etl_pipeline.py` in the classroom on the `Project Workspace IDE` coming later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
